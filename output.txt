

##tasks.py##

from celery import shared_task
from celery.exceptions import SoftTimeLimitExceeded
from flask import current_app
from .celery_worker import celery
from .models import Result
from .utils import process_text_file, extract_key_clauses
from celery.utils.log import get_task_logger
from sqlalchemy.exc import IntegrityError
from .__init__ import db

@celery.task(bind=True, max_retries=3, soft_time_limit=300, name='app.tasks.analyze_lease_document_background')
def analyze_lease_document_background(self, lease_text_dict):
    logger = get_task_logger(__name__)
    try:
        logger.info("Task started...")

        with current_app.app_context():
            logger.info("Inside app context...")

            self.update_state(state='PROCESSING', meta={'progress': 'Extracting clauses...'})
            logger.info("Extracting clauses...")

            extracted_clauses = extract_key_clauses(" ".join(lease_text_dict.values()))
            logger.info("Clauses extracted, saving to DB...")

            result = Result(clauses=extracted_clauses)
            db.session.add(result)
            db.session.commit()
            logger.info("DB commit successful!")

            self.update_state(state='SUCCESS', meta={'progress': 'Analysis complete!'})
            logger.info("Task completed successfully!")
            return {'status': 'Success', 'result_id': result.id}

    except SoftTimeLimitExceeded as e:
        current_app.logger.error(f"Soft time limit exceeded: {str(e)}")
    except IntegrityError as e:
        try:
            db.session.rollback()
        except Exception as ex:
            logger.error(f"Failed to rollback: {str(ex)}")
        logger.error(f"Database integrity error: {str(e)}")
    except Exception as e:
        try:
            db.session.rollback()
        except Exception as ex:
            logger.error(f"Failed to rollback: {str(ex)}")
        self.retry(exc=e, countdown=2 ** self.request.retries)  # exponential backoff retry
        logger.error(f"Error in task: {str(e)}")
        return {'status': 'Failure', 'error_message': str(e)}




@celery.task(bind=True)
def long_running_task(self):
    # Your task logic here...
    return 'Task completed!'

@celery.task(bind=True)
def process_text_file_task(self, file_path):
    return process_text_file(file_path)

##models.py##

from flask_sqlalchemy import SQLAlchemy

db = SQLAlchemy()


# SQLAlchemy Model
class Result(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    clauses = db.Column(db.PickleType)
    sentences = db.Column(db.PickleType)
    summarized_dict = db.Column(db.PickleType)


##celery_worker.py##

from celery import Celery
from celery.utils.log import get_task_logger

# Create a Celery instance
celery = Celery(
    'celery_worker',
    broker='redis://localhost:6380/0',
    backend='redis://localhost:6380/1'
)

# Define a task logger
logger = get_task_logger(__name__)


##__init__.py##

import os
import logging
from celery import Celery
from flask import Flask, jsonify
from flask_sqlalchemy import SQLAlchemy
from . import tasks

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

logging.basicConfig(filename='app.log', level=logging.DEBUG)  # Log to a file

# Initialize extensions
db = SQLAlchemy()

def create_celery(app: Flask) -> Celery:
    celery = Celery(
        app.import_name,
        backend='redis://localhost:6380/1',
        broker='redis://localhost:6380/0',
        include=['app.tasks']
    )
    celery.conf.update(app.config)
    return celery

def raise_exception(msg):
    assert isinstance(msg, object)
    raise ValueError(msg)

def create_app() -> object:
    app = Flask(__name__)
    app.config.update(
        SECRET_KEY=os.getenv('SECRET_KEY', 'your_secret_key'),
        CELERY_BROKER_URL=os.getenv('CELERY_BROKER_URL', 'redis://localhost:6380/0'),
        CELERY_RESULT_BACKEND=os.getenv('CELERY_RESULT_BACKEND', 'redis://localhost:6380/1'),
        SQLALCHEMY_DATABASE_URI='sqlite:///results.db',
        SQLALCHEMY_TRACK_MODIFICATIONS=False,
        UPLOAD_FOLDER='UPLOAD_FOLDER',
        broker_connection_retry_on_startup=True,
    )
    celery = create_celery(app)
    app.celery = celery

    # Assuming your blueprint is named 'bp' in your routes module
    from .routes import bp as routes_bp
    app.register_blueprint(routes_bp)

    db.init_app(app)

    # Create tables
    with app.app_context():
        db.create_all()

    @app.route('/debug_env_vars')
    def debug_env_vars():
        broker_url = os.environ.get('CELERY_BROKER_URL')
        result_backend = os.environ.get('CELERY_RESULT_BACKEND')
        env_vars = {
            'CELERY_BROKER_URL': broker_url,
            'CELERY_RESULT_BACKEND': result_backend
        }
        return jsonify(env_vars)

    return app


##get_path.py##

# get_path.py

import os
print("Current Working Directory:", os.getcwd())


##forms.py##

from flask_wtf import FlaskForm
from wtforms import FileField, SubmitField
from wtforms.validators import ValidationError

# Define WTForm validators
def validate_file(form, field):
    if field.data is None or not field.data.filename.lower().endswith('.pdf'):
        raise ValidationError('Please upload a valid PDF file.')

# WTForm Class
class LeaseForm(FlaskForm):
    lease_file = FileField('Upload Lease Document', validators=[validate_file])
    submit = SubmitField('Analyze Lease')


##utils.py##

import concurrent.futures
import re
from concurrent.futures import ThreadPoolExecutor
import joblib
from PyPDF2 import PdfFileReader
from flask import flash
from transformers import pipeline

# Load pre-trained model and vectorizer
model = joblib.load('lease_clause_classifier.pkl')
vectorizer = joblib.load('tfidf_vectorizer.pkl')

ALLOWED_EXTENSIONS = {'txt', 'pdf', 'doc', 'docx'}


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


# Ensure that vectorizer and model are defined
# from your_model_package import vectorizer, model

def process_text_file(file_path):
    try:
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                text_data = file.read()
        except UnicodeDecodeError:
            # Handle other encodings like 'ISO-8859-1', 'latin1', etc.
            with open(file_path, 'r', encoding='ISO-8859-1') as file:
                text_data = file.read()

        # Extract Information
        rent_clause_pattern = re.compile(r'Rent Clause: (.+)')
        rent_clause = re.search(rent_clause_pattern, text_data)
        extracted_data = {
            'Rent Clause': rent_clause.group(1) if rent_clause else 'Not found'
        }

        # Assume that you have functions or logic to extract clauses and sentences
        # these should be implemented based on your specific use-case and data
        clauses = extract_clauses(text_data)  # Implement this function based on your use case
        sentences = extract_sentences(text_data)  # Implement this function based on your use case

        # Apply ML Model
        vectorized_data = vectorizer.transform([text_data])
        prediction = model.predict(vectorized_data)
        print("Type of prediction: {type(prediction)}, prediction: {prediction}")  # Add this line

        # Now, ensure that prediction is indexable before proceeding.
        if isinstance(prediction, (list, tuple)) and prediction:
            extracted_data['Predicted Category'] = 'Key Term' if prediction[0] == 1 else 'Problem Clause'
        else:
            print("Unexpected prediction format: {prediction}")
            extracted_data['Predicted Category'] = 'Unknown'

        # Interpret Prediction
        extracted_data['Predicted Category'] = 'Key Term' if prediction[0] == 1 else 'Problem Clause'

        return clauses, sentences, extracted_data
    except Exception as e:
        print("Error processing text: {str(e)}")
        return None, None, {'error': str(e)}


# Placeholder for clause extraction logic, you need to define actual logic based on your needs
def extract_clauses(text):
    # Actual logic to extract clauses
    clauses = "Your clause extraction logic here"
    return clauses


# Placeholder for sentence extraction logic, you need to define actual logic based on your needs
def extract_sentences(text):
    # Actual logic to extract sentences
    sentences = "Your sentence extraction logic here"
    return sentences


# Remove or relocate the Celery task if itâ€™s not utilized or create it as per the actual use-case requirements.
# Function to extract text from a PDF file
def process_uploaded_pdf(file):
    try:
        pdf_reader = PdfFileReader(file)
        lease_text_dict = {"Page {i}": page.extract_text() for i, page in enumerate(pdf_reader.pages, start=1)}
        return lease_text_dict
    except Exception as e:
        flash("Error processing PDF: {str(e)}")
        return None


# Function to get the summarizer pipeline
def get_summarizer():
    return pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")


# Function to summarize text using the summarizer pipeline
summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")


def summarize(text_dict):
    summarizer = get_summarizer()
    summarized_dict = {}
    with ThreadPoolExecutor() as executor:
        futures = {executor.submit(summarizer, text, {"max_length": 150, "min_length": 40, "do_sample": False}): page
                   for page, text in text_dict.items()}
        for future in concurrent.futures.as_completed(futures):
            page = futures[future]
            try:
                summarized_dict[page] = future.result()[0]['summary_text']
            except Exception as e:
                print(f"Error summarizing page {page}: {str(e)}")
    return summarized_dict


# Function to extract key clauses from the lease text
def extract_key_clauses(lease_text):
    # Define regular expressions for key clauses (you can add more)
    rent_clause_pattern = re.compile(r'Rent Clause: (.+)')
    deposit_clause_pattern = re.compile(r'Deposit Clause: (.+)')
    termination_clause_pattern = re.compile(r'Termination Clause: (.+)')
    maintenance_clause_pattern = re.compile(r'Maintenance Clause: (.+)')

    # Extract key clauses using regex
    rent_clause = re.search(rent_clause_pattern, lease_text)
    deposit_clause = re.search(deposit_clause_pattern, lease_text)
    termination_clause = re.search(termination_clause_pattern, lease_text)
    maintenance_clause = re.search(maintenance_clause_pattern, lease_text)

    # Create a dictionary to store the extracted clauses
    extracted_clauses = {
        'Rent Clause': rent_clause.group(1) if rent_clause else 'Not found',
        'Deposit Clause': deposit_clause.group(1) if deposit_clause else 'Not found',
        'Termination Clause': termination_clause.group(1) if termination_clause else 'Not found',
        'Maintenance Clause': maintenance_clause.group(1) if maintenance_clause else 'Not found',
    }

    return extracted_clauses


def process_your_file(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
        return content
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='ISO-8859-1') as file:
                content = file.read()
            return content
        except Exception as e:
            print(f"Error reading file with ISO-8859-1 encoding {file_path}: {str(e)}")
            return None
    except Exception as e:
        print(f"Error processing file {file_path}: {str(e)}")
        return None


def load_model():
    return joblib.load('lease_clause_classifier.pkl')


def load_vectorizer():
    return joblib.load('tfidf_vectorizer.pkl')


##train_lease_classifier.py##

import pandas as pd
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC

# Load the data from Excel
df = pd.read_excel('lease_terms_data.xlsx', engine='openpyxl')

# Combine the 'Key Terms' and 'Problem Clauses' data
documents = df['Key Terms'].dropna().tolist() + df['Problem Clauses'].dropna().tolist()

# Labels for the data: 1 for 'Key Terms' and 0 for 'Problem Clauses'
labels = [1]*len(df['Key Terms'].dropna()) + [0]*len(df['Problem Clauses'].dropna())

# Vectorize the text data
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(documents)

# Create a Support Vector Machine (SVM) classifier
classifier = SVC(kernel='linear')

# Train the classifier
classifier.fit(X, labels)

# Save the classifier to a file
joblib.dump(classifier, 'lease_clause_classifier.pkl')

# Save the vectorizer for transforming new documents
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')

print("Classifier and vectorizer saved.")


##__main__.py##

from app.__init__ import create_app, db

app = create_app()

if __name__ == '__main__':
    with app.app_context():
        db.create_all()  # Ensure all database tables are created
    app.run(debug=True)


##routes.py##

import joblib
import os
from flask import Blueprint, render_template, flash, jsonify, current_app
from .forms import LeaseForm
from . import db  # Import db from app/__init__.py
from werkzeug.utils import secure_filename
from app.utils import allowed_file, process_text_file
from .models import Result
import traceback
from celery.exceptions import NotRegistered

bp = Blueprint('routes', __name__)

# Loading other necessary models and data
model = joblib.load('lease_clause_classifier.pkl')
tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')
KEY_CATEGORIES = ['Rent', 'Security Deposit', 'Maintenance', 'Termination']
PROBLEMATIC_CATEGORIES = ['Insurance', 'Sublease', 'Indemnity', 'Default']


@bp.route('/')
def home():
    return render_template('home.html')


@bp.route('/login')
def login():
    return render_template('login.html')


@bp.route('/register')
def register():
    return render_template('register.html')


from .tasks import analyze_lease_document_background

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@bp.route('/upload_lease', methods=['GET', 'POST'])
def upload_lease():
    form = LeaseForm()
    if form.validate_on_submit():
        file = form.lease_file.data
        if file and allowed_file(file.filename):  # Ensure allowed_file is defined
            filename = secure_filename(file.filename)
            upload_folder = current_app.config['UPLOAD_FOLDER']
            if not os.path.exists(upload_folder):
                os.makedirs(upload_folder)
            file_path = os.path.join(upload_folder, filename)

            try:
                file.save(file_path)
                logger.info("File saved successfully. About to enqueue task.")

                task = analyze_lease_document_background.apply_async(args=[file_path])  # Use apply_async
                logger.info(f"Task enqueued with ID: {task.id}")

                return jsonify({"task_id": task.id}), 202
            except Exception as e:
                error_info = traceback.format_exc()  # Get the traceback info
                logger.error(f"Error: {str(e)}\n{error_info}")  # Log error with traceback
                flash('An error occurred while uploading/processing the file.', 'error')
        else:
            flash('Invalid file type. Please upload a valid file.', 'error')
    return render_template('upload_lease.html', form=form)



@bp.route('/task-status/<task_id>')
def task_status(task_id):
    try:
        task = analyze_lease_document_background.AsyncResult(task_id)
        response_data = {
            'state': task.state,
            'result': task.info.get('result', '') if task.info else '',
            'progress': task.info.get('progress', 0) if task.info else 0,
            'error': task.info.get('error', '') if task.info else ''
        }
    except NotRegistered:
        response_data = {
            'state': 'ERROR',
            'result': '',
            'progress': 0,
            'error': f'Task with ID {task_id} not registered'
        }
    except Exception as e:
        response_data = {
            'state': 'ERROR',
            'result': '',
            'progress': 0,
            'error': str(e)
        }
    return jsonify(response_data)


@bp.route('/analysis_results/<int:result_id>', methods=['GET'])
def analysis_results(result_id):
    # TODO: Retrieve result_data using result_id from the database
    result_data = {}
    return render_template('analysis_results.html', result_data=result_data)


@bp.route('/task/<task_id>')
def background_task_status(task_id):
    from .tasks import analyze_lease_document_background
    # Ensure analyze_lease_document_background is defined in your code.
    task = analyze_lease_document_background.AsyncResult(task_id)
    if task.state == 'PENDING':
        response = {
            'state': task.state,
            'status': 'Pending...'
        }
    elif task.state != 'FAILURE':
        response = {
            'state': task.state,
            'status': str(task.info),  # this is the custom status
        }
    else:
        # something went wrong in the background job
        response = {
            'state': task.state,
            'status': str(task.info),  # this contains exception info
        }
    return jsonify(response)

def test_allowed_file():
    assert allowed_file("document.pdf")
    assert not allowed_file("document.exe")

bp.route("/healthz/db", methods=["GET"])
def check_db():
    try:
        # execute a simple query to check the database connectivity
        db.session.execute('SELECT 1;')
        return jsonify({"status": "up"}), 200
    except Exception as e:
        return jsonify({"status": "down", "error": str(e)}), 500

bp.route("/healthz/celery", methods=["GET"])
def check_celery():
    try:
        # Inspect all registered workers
        i = current_app.celery.control.inspect()
        if not i.stats():
            raise ValueError("No running Celery workers were found.")
        return jsonify({"status": "up"}), 200
    except Exception as e:
        return jsonify({"status": "down", "error": str(e)}), 500

bp.route("/healthz/broker", methods=["GET"])
def check_broker():
    try:
        # Check the broker's (e.g., Redis) connectivity
        info = current_app.celery.connection().default_channel.client.info()
        if 'redis_version' not in info:
            raise ValueError("Not connected to Redis.")
        return jsonify({"status": "up"}), 200
    except Exception as e:
        return jsonify({"status": "down", "error": str(e)}), 500
